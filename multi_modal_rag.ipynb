{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3e4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import os, json, uuid, hashlib, base64, pickle\n",
    "from base64 import b64decode\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI as VisionModel\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bc0323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171205/2829385433.py:11: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  EMBEDDINGS = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "SOURCE_DIR = Path(\"source_docs\")\n",
    "HASH_FILE = Path(\"output/hashes.json\")\n",
    "VSTORE_DIR = Path(\"output/vectorstore\")\n",
    "DOCSTORE_PATH = Path(\"output/docstore/docstore.pkl\")\n",
    "\n",
    "# Create necessary directories\n",
    "VSTORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DOCSTORE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "HASH_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "EMBEDDINGS = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f8fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_hash(filepath: Path) -> str:\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        hasher.update(f.read())\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def load_hashes(json_path: Path) -> dict:\n",
    "    if json_path.exists():\n",
    "        with open(json_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_hashes(hashes: dict, json_path: Path):\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(hashes, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13782715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_elements(filepath: str):\n",
    "    chunks = partition_pdf(\n",
    "        filename=filepath,\n",
    "        infer_table_structure=True,\n",
    "        strategy=\"hi_res\",\n",
    "        extract_image_block_types=[\"Image\"],\n",
    "        extract_image_block_to_payload=True,\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=10000,\n",
    "        combine_text_under_n_chars=2000,\n",
    "        new_after_n_chars=6000,\n",
    "    )\n",
    "    tables, texts, images = [], [], []\n",
    "    for chunk in chunks:\n",
    "        if \"CompositeElement\" in str(type(chunk)):\n",
    "            for el in chunk.metadata.orig_elements:\n",
    "                if \"Table\" in str(type(el)):\n",
    "                    tables.append(el)\n",
    "                elif \"Image\" in str(type(el)):\n",
    "                    images.append(el.metadata.image_base64)\n",
    "            texts.append(chunk)\n",
    "    return texts, tables, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c3b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_table_chain():\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an assistant tasked with summarizing tables and text.\n",
    "    Give a concise summary of the table or text.\n",
    "    Respond only with the summary, no additional comment.\n",
    "    Table or text chunk: {element}\n",
    "    \"\"\")\n",
    "    model = ChatOpenAI(temperature=0.5, model=\"gpt-4.1-mini\")\n",
    "    return {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41df8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_chain():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"user\", [\n",
    "            {\"type\": \"text\", \"text\": \"Describe the image in detail. For context, it's from a trust fund report. Be specific.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"}}\n",
    "        ])\n",
    "    ])\n",
    "    model = VisionModel(model=\"gpt-4.1-mini\")\n",
    "    return prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbc7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorstore(vstore_dir):\n",
    "    if not any(Path(vstore_dir).glob(\"*\")):\n",
    "        return Chroma(collection_name=\"multi_modal_rag\", persist_directory=str(vstore_dir), embedding_function=EMBEDDINGS)\n",
    "    try:\n",
    "        return Chroma(collection_name=\"multi_modal_rag\", persist_directory=str(vstore_dir), embedding_function=EMBEDDINGS)\n",
    "    except Exception:\n",
    "        import shutil\n",
    "        shutil.rmtree(vstore_dir, ignore_errors=True)\n",
    "        return Chroma(collection_name=\"multi_modal_rag\", persist_directory=str(vstore_dir), embedding_function=EMBEDDINGS)\n",
    "\n",
    "def load_docstore(docstore_path):\n",
    "    if docstore_path.exists():\n",
    "        with open(docstore_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return InMemoryStore()\n",
    "\n",
    "def save_docstore(docstore, docstore_path):\n",
    "    with open(docstore_path, \"wb\") as f:\n",
    "        pickle.dump(docstore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47dd6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_documents_to_retriever(retriever, elements, summaries, filename, id_key=\"doc_id\"):\n",
    "    if not elements or not summaries or len(elements) == 0 or len(summaries) == 0:\n",
    "        print(f\"‚ö†Ô∏è Skipping empty documents for: {filename} | {id_key}\")\n",
    "        return\n",
    "\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in elements]\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=summaries[i],\n",
    "            metadata={id_key: doc_ids[i], \"source_file\": filename},\n",
    "        )\n",
    "        for i in range(len(elements))\n",
    "    ]\n",
    "\n",
    "    if len(docs) == 0:\n",
    "        print(f\"‚ö†Ô∏è Skipped adding empty document list to retriever for {filename}\")\n",
    "        return\n",
    "\n",
    "    retriever.vectorstore.add_documents(docs)\n",
    "    retriever.docstore.mset(list(zip(doc_ids, elements)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b344d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171205/51604295.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  return Chroma(collection_name=\"multi_modal_rag\", persist_directory=str(vstore_dir), embedding_function=EMBEDDINGS)\n"
     ]
    }
   ],
   "source": [
    "# Load stores\n",
    "vectorstore = load_vectorstore(VSTORE_DIR)\n",
    "docstore = load_docstore(DOCSTORE_PATH)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=\"doc_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d13ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171205/3483198702.py:8: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(temperature=0.5, model=\"gpt-4.1-mini\")\n"
     ]
    }
   ],
   "source": [
    "# Load chains\n",
    "text_table_chain = get_text_table_chain()\n",
    "image_chain = get_image_chain()\n",
    "file_hashes = load_hashes(HASH_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f0944c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÑ Processing PDFs:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÑ Processing PDFs:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Skipping (already processed): 2020TrustFundAnnualReports.pdf\n",
      "‚úÖ Skipping (already processed): 2021TrustFundAnnualReports.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÑ Processing PDFs:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Skipping (already processed): 2022TrustFundAnnualReports.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÑ Processing PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Skipping (already processed): 2023TrustFundAnnualReports.pdf\n",
      "‚úÖ Skipping (already processed): 2024TrustFundAnnualReports.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for filepath in tqdm(list(SOURCE_DIR.glob(\"*.pdf\")), desc=\"üìÑ Processing PDFs\"):\n",
    "    file_hash = get_file_hash(filepath)\n",
    "    if file_hashes.get(filepath.name) == file_hash:\n",
    "        tqdm.write(f\"‚úÖ Skipping (already processed): {filepath.name}\")\n",
    "        continue\n",
    "\n",
    "    tqdm.write(f\"üß© Processing new or updated: {filepath.name}\")\n",
    "    try:\n",
    "        texts, tables, images = parse_pdf_elements(str(filepath))\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"‚ùå Failed to parse {filepath.name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    text_summaries = text_table_chain.batch(texts, {\"max_concurrency\": 3})\n",
    "    table_summaries = text_table_chain.batch([t.metadata.text_as_html for t in tables], {\"max_concurrency\": 3})\n",
    "    image_summaries = image_chain.batch(images)\n",
    "\n",
    "    add_documents_to_retriever(retriever, texts, text_summaries, filepath.name)\n",
    "    add_documents_to_retriever(retriever, tables, table_summaries, filepath.name)\n",
    "    add_documents_to_retriever(retriever, images, image_summaries, filepath.name)\n",
    "\n",
    "    file_hashes[filepath.name] = file_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58cf48f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171205/2610969097.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done: Vectorstore and docstore saved.\n"
     ]
    }
   ],
   "source": [
    "vectorstore.persist()\n",
    "save_docstore(docstore, DOCSTORE_PATH)\n",
    "save_hashes(file_hashes, HASH_FILE)\n",
    "print(\"‚úÖ Done: Vectorstore and docstore saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942b2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs(docs):\n",
    "    b64, text = [], []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            b64decode(doc)\n",
    "            b64.append(doc)\n",
    "        except Exception:\n",
    "            text.append(doc)\n",
    "    return {\"images\": b64, \"texts\": text}\n",
    "\n",
    "def build_prompt(kwargs):\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "\n",
    "    context_text = \"\".join([t.text for t in docs_by_type[\"texts\"]])\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question based only on the following context, which can include text, tables, and the below image.\n",
    "    Context: {context_text}\n",
    "    Question: {user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template.strip()}]\n",
    "    for image in docs_by_type[\"images\"]:\n",
    "        prompt_content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"}})\n",
    "\n",
    "    return ChatPromptTemplate.from_messages([HumanMessage(content=prompt_content)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b4a0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mm_rag_chain(retriever):\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever | RunnableLambda(parse_docs),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | RunnableLambda(build_prompt)\n",
    "        | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "def get_mm_rag_chain_with_sources(retriever):\n",
    "    return {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    } | RunnablePassthrough().assign(\n",
    "        response=(\n",
    "            RunnableLambda(build_prompt)\n",
    "            | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbbd335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_mm_rag_chain(retriever)\n",
    "chain_with_sources = get_mm_rag_chain_with_sources(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37343b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Answer:\n",
      "Major replenishments in Financial Intermediary Funds (FIFs) have occurred in chronological order, with specific pledging sessions and amounts associated with each fund. Here‚Äôs a summary of the key replenishments:\n",
      "\n",
      "1. **Global Fund**\n",
      "   - **Pledging Session:** October 2019\n",
      "   - **Replenishment Cycle Period:** FY2020‚Äì22\n",
      "   - **Amount:** $14.0 billion\n",
      "   - **Previous Replenishment:** FY2017‚Äì19\n",
      "\n",
      "2. **Green Climate Fund (GCF)**\n",
      "   - **Pledging Session:** October 2019\n",
      "   - **Replenishment Cycle Period:** FY2020‚Äì23\n",
      "   - **Amount:** $10.0 billion\n",
      "   - **Previous Replenishment:** FY2015‚Äì19\n",
      "\n",
      "3. **Global Agriculture and Food Security Program (GAFSP)**\n",
      "   - **Pledging Session:** October 2020\n",
      "   - **Replenishment Cycle Period:** FY2020‚Äì25\n",
      "   - **Amount:** $1.5 billion\n",
      "   - **Previous Replenishment:** FY2010‚Äì20\n",
      "\n",
      "4. **Global Partnership for Education (GPE)**\n",
      "   - **Pledging Session:** July 2021\n",
      "   - **Replenishment Cycle Period:** CY2021‚Äì25\n",
      "   - **Amount:** $4.0 billion\n",
      "   - **Previous Replenishment:** CY2018‚Äì20\n",
      "\n",
      "5. **Tentative Upcoming Replenishments:**\n",
      "   - **Climate Investment Funds (CIF)**\n",
      "     - **Replenishment Cycle Period:** FY2020‚Äì22\n",
      "     - **Amount:** $8.0 billion (representing pledges since inception)\n",
      "   - **Global Environment Facility (GEF)**\n",
      "     - **Pledging Session:** Spring 2022\n",
      "     - **Replenishment Cycle Period:** FY2022‚Äì26\n",
      "     - **Amount:** $4.1 billion\n",
      "     - **Previous Replenishment:** FY2018‚Äì22\n",
      "\n",
      "These replenishments reflect significant financial commitments aimed at addressing global challenges in health, climate, education, and food security.\n"
     ]
    }
   ],
   "source": [
    "question = \"tell me about major replenishments in FIFs\"\n",
    "response = chain.invoke(question)\n",
    "print(f\"\\nüß† Answer:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-chroma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
