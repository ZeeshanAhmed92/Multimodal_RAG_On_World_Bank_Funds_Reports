{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9708e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import fitz\n",
    "import uuid\n",
    "import hashlib\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d523803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file for Azure keys/config\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65e9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set path to tesseract executable on Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dddf996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI config\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\")  # e.g. text-embedding-3-small\n",
    "LLM_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_LLM_DEPLOYMENT\")          # e.g. gpt-4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e37895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# OPENAI_EMBEDDING_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\") \n",
    "# OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1401f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Setup Azure Embeddings & LLM\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    chunk_size=1000,  # ‚úÖ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceeda2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(\n",
    "#     model=OPENAI_EMBEDDING_MODEL,\n",
    "#     openai_api_key=OPENAI_API_KEY\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0701b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")  # Or \"all-minilm\" or \"bge-base-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c80cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Path Configs ===\n",
    "PDF_DIR = \"./source_docs\"\n",
    "CHAT_HISTORY_DIR = \"chat_history\"\n",
    "FAISS_INDEX_PATH = \"./store\"  # ‚úÖ Now points directly to where index.faiss is\n",
    "METADATA_STORE_PATH = \"./store/index.pkl\"  # ‚úÖ Points to the actual pickle file\n",
    "HASH_STORE_PATH = \"./hashes/index_hashes.txt\"\n",
    "TEXT_CACHE_DIR = \"./text_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr(pdf_path):\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    md_filename = os.path.splitext(filename)[0] + \".md\"\n",
    "    md_path = os.path.join(TEXT_CACHE_DIR, md_filename)\n",
    "\n",
    "    # If cached .md file exists, read it\n",
    "    if os.path.exists(md_path):\n",
    "        print(f\"üìÑ Cached text found for {filename}, loading from Markdown.\")\n",
    "        with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    print(f\"üîç OCR processing: {filename}\")\n",
    "    full_text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        full_text += f\"\\n\\n## Page {page_num + 1} Text\\n{text.strip()}\"\n",
    "\n",
    "        try:\n",
    "            pix = page.get_pixmap(dpi=300)\n",
    "            image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            ocr_text = pytesseract.image_to_string(image)\n",
    "            full_text += f\"\\n\\n## Page {page_num + 1} OCR\\n{ocr_text.strip()}\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è OCR failed on page {page_num + 1}: {e}\")\n",
    "\n",
    "    # Save as markdown in readable form\n",
    "    os.makedirs(TEXT_CACHE_DIR, exist_ok=True)\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f_md:\n",
    "        f_md.write(full_text)\n",
    "\n",
    "    return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c94a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(filename):\n",
    "    match = re.search(r\"(20\\d{2})\", filename)\n",
    "    return match.group(1) if match else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef51dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_hash(filepath):\n",
    "    \"\"\"Generate SHA256 hash of a file.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        while chunk := f.read(8192):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_existing_hashes():\n",
    "    \"\"\"Load file hashes from index_hashes.txt.\"\"\"\n",
    "    if not os.path.exists(HASH_STORE_PATH):\n",
    "        return set()\n",
    "    with open(HASH_STORE_PATH, \"r\") as f:\n",
    "        return set(line.strip() for line in f.readlines())\n",
    "\n",
    "def save_hashes(hashes: set):\n",
    "    \"\"\"Save updated hashes to index_hashes.txt.\"\"\"\n",
    "    with open(HASH_STORE_PATH, \"w\") as f:\n",
    "        for h in sorted(hashes):\n",
    "            f.write(f\"{h}\\n\")\n",
    "\n",
    "def enrich_metadata(filename: str) -> dict:\n",
    "    year_match = re.search(r\"(20\\d{2})\", filename)\n",
    "    return {\n",
    "        \"source\": filename,\n",
    "        \"year\": year_match.group(1) if year_match else \"Unknown\",\n",
    "        \"fund\": \"UTF\",\n",
    "        \"doc_type\": \"Annual Report\"\n",
    "    }\n",
    "\n",
    "def update_faiss_index(embeddings):\n",
    "    print(\"üîÑ Checking for new documents...\")\n",
    "    \n",
    "    # Load known hashes\n",
    "    existing_hashes = load_existing_hashes()\n",
    "    new_hashes = set()\n",
    "    new_documents = []\n",
    "\n",
    "    for filename in os.listdir(PDF_DIR):\n",
    "        if not filename.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        pdf_path = os.path.join(PDF_DIR, filename)\n",
    "        file_digest = file_hash(pdf_path)\n",
    "\n",
    "        if file_digest in existing_hashes:\n",
    "            print(f\"‚è≠Ô∏è Skipping already indexed: {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üìÑ New PDF detected: {filename}\")\n",
    "        text = extract_text_with_ocr(pdf_path)\n",
    "        metadata = enrich_metadata(filename)\n",
    "        new_documents.append(Document(page_content=text, metadata=metadata))\n",
    "        new_hashes.add(file_digest)\n",
    "\n",
    "    # No new docs? Load and return existing vector store\n",
    "    if not new_documents:\n",
    "        print(\"‚úÖ No new documents found.\")\n",
    "        return FAISS.load_local(FAISS_INDEX_PATH, embeddings)\n",
    "\n",
    "    print(\"‚úÇÔ∏è Splitting documents...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=100,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "    )\n",
    "    new_chunks = splitter.split_documents(new_documents)\n",
    "\n",
    "    print(\"üì¶ Updating FAISS vector store...\")\n",
    "    if os.path.exists(FAISS_INDEX_PATH + \".faiss\"):\n",
    "        vectorstore = FAISS.load_local(FAISS_INDEX_PATH, embeddings)\n",
    "        vectorstore.add_documents(new_chunks)\n",
    "    else:\n",
    "        vectorstore = FAISS.from_documents(new_chunks, embeddings)\n",
    "\n",
    "    vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "\n",
    "    # Save combined hashes\n",
    "    updated_hashes = existing_hashes.union(new_hashes)\n",
    "    save_hashes(updated_hashes)\n",
    "    print(f\"‚úÖ Stored {len(updated_hashes)} file hashes in {HASH_STORE_PATH}\")\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_vectorstore(embeddings):\n",
    "    return update_faiss_index(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6db16815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistentChatMessageHistory(ChatMessageHistory):\n",
    "    def __init__(self, session_id: str):\n",
    "        super().__init__()\n",
    "        self._session_id = session_id\n",
    "        self._file_path = os.path.join(CHAT_HISTORY_DIR, f\"{session_id}.json\")\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        if os.path.exists(self._file_path):\n",
    "            with open(self._file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw = json.load(f)\n",
    "                self.messages = [self._dict_to_message(msg) for msg in raw]\n",
    "\n",
    "    def save(self):\n",
    "        with open(self._file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([self._message_to_dict(msg) for msg in self.messages], f, indent=2)\n",
    "\n",
    "    def add_message(self, message):\n",
    "        super().add_message(message)\n",
    "        self.save()\n",
    "\n",
    "    def _message_to_dict(self, message):\n",
    "        return {\"type\": message.type, \"content\": message.content}   \n",
    "\n",
    "    def _dict_to_message(self, data):\n",
    "        from langchain_core.messages import HumanMessage, AIMessage\n",
    "        return HumanMessage(content=data[\"content\"]) if data[\"type\"] == \"human\" else AIMessage(content=data[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a136b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create RAG Chain with Story Extraction Prompt ===\n",
    "def setup_rag_chain_with_history(session_id: str, embeddings):\n",
    "    vectorstore = load_or_create_vectorstore(embeddings)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 7})\n",
    "\n",
    "    # llm = ChatOpenAI(\n",
    "    # model=OPENAI_MODEL,\n",
    "    # temperature=0,\n",
    "    # openai_api_key=OPENAI_API_KEY\n",
    "    # )\n",
    "    # llm = Ollama(model=\"llama3.2:latest\")  # or any model like \"mistral\", \"phi3\", etc.\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=LLM_DEPLOYMENT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         \"You are an AI assistant trained to extract and summarize *results stories* from UTF annual reports. \"\n",
    "         \"Each story includes outcomes, donors, regions, sectors, and beneficiaries. \"\n",
    "         \"From the documents, identify such stories and return:\"\n",
    "         \"‚Ä¢ Title/Headline\\n\"\n",
    "         \"‚Ä¢ Region\\n\"\n",
    "         \"‚Ä¢ Sector\\n\"\n",
    "         \"‚Ä¢ Donor/Fund\\n\"\n",
    "         \"‚Ä¢ Results/Impact Summary\\n\"\n",
    "         \"‚Ä¢ Source Document and Page if available\\n\"\n",
    "         \"If no story is found, reply: 'No story found.'\\n\\n{context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    return RunnableWithMessageHistory(\n",
    "        rag_chain,\n",
    "        lambda session_id: PersistentChatMessageHistory(session_id),\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d96ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run a Query ===\n",
    "def run_query(session_id: str, question: str):\n",
    "    rag_chain = setup_rag_chain_with_history(session_id, embeddings)\n",
    "    result = rag_chain.invoke(\n",
    "        {\"input\": question},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e3e172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " give me two examples of how the MDTF supported private sector job creation in 2020\n",
      "üîÑ Checking for new documents...\n",
      "üìÑ New PDF detected: 2020TrustFundAnnualReports.pdf\n",
      "üîç Processing: 2020TrustFundAnnualReports.pdf\n",
      "üìÑ New PDF detected: 2021TrustFundAnnualReports.pdf\n",
      "üîç Processing: 2021TrustFundAnnualReports.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m q = \u001b[33m\"\u001b[39m\u001b[33mgive me two examples of how the MDTF supported private sector job creation in 2020\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m answer = \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müß† \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mrun_query\u001b[39m\u001b[34m(session_id, question)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_query\u001b[39m(session_id: \u001b[38;5;28mstr\u001b[39m, question: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     rag_chain = \u001b[43msetup_rag_chain_with_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     result = rag_chain.invoke(\n\u001b[32m      5\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: question},\n\u001b[32m      6\u001b[39m         config={\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m: session_id}}\n\u001b[32m      7\u001b[39m     )\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36msetup_rag_chain_with_history\u001b[39m\u001b[34m(session_id, embeddings)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_rag_chain_with_history\u001b[39m(session_id: \u001b[38;5;28mstr\u001b[39m, embeddings):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     vectorstore = \u001b[43mload_or_create_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     retriever = vectorstore.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m7\u001b[39m})\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# llm = ChatOpenAI(\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# model=OPENAI_MODEL,\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# temperature=0,\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# openai_api_key=OPENAI_API_KEY\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# llm = Ollama(model=\"llama3.2:latest\")  # or any model like \"mistral\", \"phi3\", etc.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mload_or_create_vectorstore\u001b[39m\u001b[34m(embeddings)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_or_create_vectorstore\u001b[39m(embeddings):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdate_faiss_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mupdate_faiss_index\u001b[39m\u001b[34m(embeddings)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìÑ New PDF detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m text = \u001b[43mextract_text_with_ocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m metadata = enrich_metadata(filename)\n\u001b[32m     53\u001b[39m new_documents.append(Document(page_content=text, metadata=metadata))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mextract_text_with_ocr\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     34\u001b[39m     pix = page.get_pixmap(dpi=\u001b[32m300\u001b[39m)\n\u001b[32m     35\u001b[39m     image = Image.frombytes(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m, [pix.width, pix.height], pix.samples)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     ocr_text = \u001b[43mpytesseract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     full_text += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m## Page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m OCR\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mocr_text.strip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[39m, in \u001b[36mimage_to_string\u001b[39m\u001b[34m(image, lang, config, nice, output_type, timeout)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[39m, in \u001b[36mimage_to_string.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    487\u001b[39m     Output.BYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(*(args + [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[32m    488\u001b[39m     Output.DICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: run_and_get_output(*args)},\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     Output.STRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    490\u001b[39m }[output_type]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[39m, in \u001b[36mrun_and_get_output\u001b[39m\u001b[34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[32m    342\u001b[39m     kwargs = {\n\u001b[32m    343\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minput_filename\u001b[39m\u001b[33m'\u001b[39m: input_filename,\n\u001b[32m    344\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m: temp_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m: timeout,\n\u001b[32m    350\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[32m    354\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         return_bytes,\n\u001b[32m    356\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pytesseract\\pytesseract.py:282\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror_string\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreturncode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mraise\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTesseractError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreturncode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pytesseract\\pytesseract.py:144\u001b[39m, in \u001b[36mtimeout_manager\u001b[39m\u001b[34m(proc, seconds)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seconds:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\subprocess.py:1209\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1206\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1211\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\subprocess.py:1628\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   1624\u001b[39m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[32m   1625\u001b[39m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[32m   1626\u001b[39m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[32m   1627\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1628\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstdout_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1629\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout_thread.is_alive():\n\u001b[32m   1630\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m.args, orig_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\threading.py:1147\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1149\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1150\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\threading.py:1167\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1168\u001b[39m         lock.release()\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "session_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "q = \"give me two examples of how the MDTF supported private sector job creation in 2020\" \n",
    "\n",
    "print(f\"\\n {q}\")\n",
    "answer = run_query(session_id, q)\n",
    "print(f\"üß† {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
