{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9708e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import fitz\n",
    "import uuid\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d523803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file for Azure keys/config\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d65e9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set path to tesseract executable on Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8e37895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI config\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-02-15-preview\"\n",
    "EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\")  # e.g. text-embedding-3-small\n",
    "LLM_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_LLM_DEPLOYMENT\")          # e.g. gpt-4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ceeda2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Setup Azure Embeddings & LLM\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    chunk_size=1000  # ‚úÖ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2c80cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Path Configs ===\n",
    "PDF_DIR = \"./source_docs\"\n",
    "CHAT_HISTORY_DIR = \"chat_history\"\n",
    "FAISS_INDEX_PATH = \"./store\"  # ‚úÖ Now points directly to where index.faiss is\n",
    "METADATA_STORE_PATH = \"./store/index.pkl\"  # ‚úÖ Points to the actual pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4e3f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Text Extraction Function ===\n",
    "def extract_text_with_ocr(pdf_path):\n",
    "    print(f\"üîç Processing: {os.path.basename(pdf_path)}\")\n",
    "    full_text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        full_text += f\"\\n\\n## Page {page_num + 1} Text\\n{text.strip()}\"\n",
    "\n",
    "        # Fallback OCR\n",
    "        try:\n",
    "            pix = page.get_pixmap(dpi=300)\n",
    "            image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            ocr_text = pytesseract.image_to_string(image)\n",
    "            full_text += f\"\\n\\n## Page {page_num + 1} OCR\\n{ocr_text.strip()}\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è OCR failed on page {page_num + 1}: {e}\")\n",
    "\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2d38feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(embeddings):\n",
    "    documents = []\n",
    "    for filename in os.listdir(PDF_DIR):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(PDF_DIR, filename)\n",
    "            print(f\"üìÑ Processing: {filename}\")\n",
    "            content = extract_text_with_ocr(pdf_path)\n",
    "            documents.append(Document(page_content=content, metadata={\"source\": filename}))\n",
    "\n",
    "    print(\"‚úÇÔ∏è Splitting documents semantically...\")\n",
    "    splitter = SemanticChunker(embeddings=embeddings)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "\n",
    "    print(\"üì¶ Creating FAISS vector store...\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "\n",
    "    with open(METADATA_STORE_PATH, \"wb\") as f:\n",
    "        pickle.dump([doc.page_content for doc in chunks], f)\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5fd097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_vectorstore(embeddings):\n",
    "    faiss_index_file = os.path.join(FAISS_INDEX_PATH, \"index.faiss\")\n",
    "    metadata_file = METADATA_STORE_PATH\n",
    "\n",
    "    if os.path.exists(faiss_index_file) and os.path.exists(metadata_file):\n",
    "        print(\"‚úÖ Loading existing FAISS vector store...\")\n",
    "        return FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        print(\"‚öôÔ∏è No existing index found. Building FAISS index from PDFs...\")\n",
    "        return build_faiss_index(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db16815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistentChatMessageHistory(ChatMessageHistory):\n",
    "    def __init__(self, session_id: str):\n",
    "        super().__init__()\n",
    "        self._session_id = session_id\n",
    "        self._file_path = os.path.join(CHAT_HISTORY_DIR, f\"{session_id}.json\")\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        if os.path.exists(self._file_path):\n",
    "            with open(self._file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw = json.load(f)\n",
    "                self.messages = [self._dict_to_message(msg) for msg in raw]\n",
    "\n",
    "    def save(self):\n",
    "        with open(self._file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([self._message_to_dict(msg) for msg in self.messages], f, indent=2)\n",
    "\n",
    "    def add_message(self, message):\n",
    "        super().add_message(message)\n",
    "        self.save()\n",
    "\n",
    "    def _message_to_dict(self, message):\n",
    "        return {\"type\": message.type, \"content\": message.content}\n",
    "\n",
    "    def _dict_to_message(self, data):\n",
    "        from langchain_core.messages import HumanMessage, AIMessage\n",
    "        return HumanMessage(content=data[\"content\"]) if data[\"type\"] == \"human\" else AIMessage(content=data[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a136b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create RAG Chain with History ===\n",
    "def setup_rag_chain_with_history(session_id: str, embeddings):\n",
    "    vectorstore = load_or_create_vectorstore(embeddings)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=LLM_DEPLOYMENT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant answering questions based on the following documents:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    return RunnableWithMessageHistory(\n",
    "        rag_chain,\n",
    "        lambda session_id: PersistentChatMessageHistory(session_id),\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40d96ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run a Query ===\n",
    "def run_query(session_id: str, question: str):\n",
    "    rag_chain = setup_rag_chain_with_history(session_id, embeddings)\n",
    "    result = rag_chain.invoke(\n",
    "        {\"input\": question},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e3e172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì give me 2020 program highlights\n",
      "‚úÖ Loading existing FAISS vector store...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\"PersistentChatMessageHistory\" object has no field \"path\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m q = \u001b[33m\"\u001b[39m\u001b[33mgive me 2020 program highlights\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚ùì \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m answer = \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müß† \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mrun_query\u001b[39m\u001b[34m(session_id, question)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_query\u001b[39m(session_id: \u001b[38;5;28mstr\u001b[39m, question: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      3\u001b[39m     rag_chain = setup_rag_chain_with_history(session_id, embeddings)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     result = \u001b[43mrag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msession_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5433\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m   5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.invoke(\n\u001b[32m   5432\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m5433\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   5434\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5435\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\langchain_core\\runnables\\history.py:596\u001b[39m, in \u001b[36mRunnableWithMessageHistory._merge_configs\u001b[39m\u001b[34m(self, *configs)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expected_keys) == \u001b[32m1\u001b[39m:\n\u001b[32m    594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parameter_names:\n\u001b[32m    595\u001b[39m         \u001b[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m         message_history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_session_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    599\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    600\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36msetup_rag_chain_with_history.<locals>.<lambda>\u001b[39m\u001b[34m(session_id)\u001b[39m\n\u001b[32m     20\u001b[39m document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n\u001b[32m     21\u001b[39m rag_chain = create_retrieval_chain(retriever, document_chain)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m RunnableWithMessageHistory(\n\u001b[32m     24\u001b[39m     rag_chain,\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m session_id: \u001b[43mPersistentChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     26\u001b[39m     input_messages_key=\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     history_messages_key=\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m     output_messages_key=\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mPersistentChatMessageHistory.__init__\u001b[39m\u001b[34m(self, session_id)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, session_id: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m = os.path.join(CHAT_HISTORY_DIR, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mself\u001b[39m.load()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zeeshan Ahmed\\Desktop\\My data\\RAG_System_Using_Funds_Annual_Reports\\rag_implementation\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
      "\u001b[31mValueError\u001b[39m: \"PersistentChatMessageHistory\" object has no field \"path\""
     ]
    }
   ],
   "source": [
    "session_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "q = \"give me 2020 program highlights\"\n",
    "\n",
    "print(f\"\\n‚ùì {q}\")\n",
    "answer = run_query(session_id, q)\n",
    "print(f\"üß† {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
