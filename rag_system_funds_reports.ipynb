{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9708e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import hashlib\n",
    "import fitz\n",
    "import uuid\n",
    "import platform\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d523803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file for Azure keys/config\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d65e9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set path to tesseract executable on Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1633a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI config\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_MODEL=\"gpt-4.1-mini\"\n",
    "OPENAI_EMBEDDING_MODEL=\"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dddf996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Azure OpenAI config\n",
    "# AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "# EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\")  \n",
    "# LLM_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_LLM_DEPLOYMENT\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1401f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Setup Azure Embeddings & LLM\n",
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "#     openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "#     openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "#     azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "#     chunk_size=1000,  # ‚úÖ \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c80cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Path Configs ===\n",
    "PDF_DIR = \"./source_docs\"\n",
    "CHAT_HISTORY_DIR = \"chat_history\"\n",
    "FAISS_INDEX_PATH = \"./store\"  # ‚úÖ Now points directly to where index.faiss is\n",
    "METADATA_STORE_PATH = \"./store/index.pkl\"  # ‚úÖ Points to the actual pickle file\n",
    "HASH_STORE_PATH = \"./hashes/index_hashes.txt\"\n",
    "TEXT_CACHE_DIR = \"./text_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee2e2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_tesseract_path():\n",
    "    system = platform.system()\n",
    "    if system == \"Windows\":\n",
    "        # Common default install location‚Äîchange if needed\n",
    "        possible = [\n",
    "            r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\",\n",
    "            r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
    "        ]\n",
    "        for path in possible:\n",
    "            if os.path.isfile(path):\n",
    "                pytesseract.pytesseract.tesseract_cmd = path\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Tesseract not found in default Windows paths.\")\n",
    "    else:\n",
    "        # On Linux or macOS, tesseract should be in PATH\n",
    "        pytesseract.pytesseract.tesseract_cmd = \"tesseract\"\n",
    "\n",
    "    # Optional: verify it's working\n",
    "    try:\n",
    "        version = os.popen(f'\"{pytesseract.pytesseract.tesseract_cmd}\" --version').read()\n",
    "        print(\"‚úîÔ∏è Tesseract detected:\", version.splitlines()[0])\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error verifying Tesseract at '{pytesseract.pytesseract.tesseract_cmd}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcfa1260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path_or_bytes):\n",
    "    configure_tesseract_path()\n",
    "\n",
    "    if isinstance(image_path_or_bytes, bytes):\n",
    "        image = Image.open(io.BytesIO(image_path_or_bytes))\n",
    "    else:\n",
    "        image = Image.open(image_path_or_bytes)\n",
    "\n",
    "    # Step 1: OCR text extraction\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "\n",
    "    # Step 2: Prepare image for OpenAI\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    b64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "    data_uri = f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "    # Step 3: LLM-based image description\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",  # Make sure this is a vision-capable model\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    image_description = response.choices[0].message.content\n",
    "\n",
    "    # Step 4: Combine and return\n",
    "    return f\"{ocr_text.strip()}\\n\\n**Image Description:**\\n{image_description.strip()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d165429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_as_markdown(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    markdown = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        markdown += f\"\\n## Page {page_num + 1}\\n\"\n",
    "        markdown += page.get_text(\"text\") + \"\\n\"\n",
    "\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            ext = base_image[\"ext\"]\n",
    "            image_filename = f\"page{page_num+1}_img{img_index+1}.{ext}\"\n",
    "\n",
    "            # Save image\n",
    "            with open(image_filename, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "\n",
    "            # OCR image text\n",
    "            ocr_text = extract_text_from_image(image_bytes)\n",
    "            markdown += f\"\\n**Image {img_index + 1} OCR:**\\n```\\n{ocr_text.strip()}\\n```\\n\"\n",
    "            markdown += f\"![Image {img_index + 1}]({image_filename})\\n\"\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63ffed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs_to_markdown(pdf_dir=PDF_DIR, output_dir=\"markdown_output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        print(f\"üìÑ Processing: {pdf_file}...\")\n",
    "\n",
    "        try:\n",
    "            markdown = extract_pdf_as_markdown(pdf_path)\n",
    "\n",
    "            # Create filename-safe version\n",
    "            base_filename = os.path.splitext(pdf_file)[0]\n",
    "            safe_name = re.sub(r\"[^\\w\\-_. ]\", \"_\", base_filename)\n",
    "            md_path = os.path.join(output_dir, f\"{safe_name}.md\")\n",
    "\n",
    "            with open(md_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "                md_file.write(markdown)\n",
    "\n",
    "            print(f\"‚úÖ Markdown saved: {md_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to process {pdf_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c8f0143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing: 2020TrustFundAnnualReports.pdf...\n",
      "‚úîÔ∏è Tesseract detected: tesseract v5.5.0.20241111\n",
      "‚ùå Failed to process 2020TrustFundAnnualReports.pdf: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "üìÑ Processing: 2021TrustFundAnnualReports.pdf...\n",
      "‚úîÔ∏è Tesseract detected: tesseract v5.5.0.20241111\n",
      "‚ùå Failed to process 2021TrustFundAnnualReports.pdf: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "üìÑ Processing: 2022TrustFundAnnualReports.pdf...\n",
      "‚úîÔ∏è Tesseract detected: tesseract v5.5.0.20241111\n",
      "‚ùå Failed to process 2022TrustFundAnnualReports.pdf: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "üìÑ Processing: 2023TrustFundAnnualReports.pdf...\n",
      "‚úîÔ∏è Tesseract detected: tesseract v5.5.0.20241111\n",
      "‚ùå Failed to process 2023TrustFundAnnualReports.pdf: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "üìÑ Processing: 2024TrustFundAnnualReports.pdf...\n",
      "‚úîÔ∏è Tesseract detected: tesseract v5.5.0.20241111\n",
      "‚ùå Failed to process 2024TrustFundAnnualReports.pdf: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "# Run the processing function\n",
    "process_all_pdfs_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c94a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(filename):\n",
    "    match = re.search(r\"(20\\d{2})\", filename)\n",
    "    return match.group(1) if match else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_hash(filepath):\n",
    "    \"\"\"Generate SHA256 hash of a file.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        while chunk := f.read(8192):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_existing_hashes():\n",
    "    \"\"\"Load file hashes from index_hashes.txt.\"\"\"\n",
    "    if not os.path.exists(HASH_STORE_PATH):\n",
    "        return set()\n",
    "    with open(HASH_STORE_PATH, \"r\") as f:\n",
    "        return set(line.strip() for line in f.readlines())\n",
    "\n",
    "def save_hashes(hashes: set):\n",
    "    \"\"\"Save updated hashes to index_hashes.txt.\"\"\"\n",
    "    with open(HASH_STORE_PATH, \"w\") as f:\n",
    "        for h in sorted(hashes):\n",
    "            f.write(f\"{h}\\n\")\n",
    "\n",
    "def update_faiss_index(embeddings):\n",
    "    print(\"üîÑ Checking for new documents...\")\n",
    "    \n",
    "    # Load known hashes\n",
    "    existing_hashes = load_existing_hashes()\n",
    "    new_hashes = set()\n",
    "    new_documents = []\n",
    "\n",
    "    for filename in os.listdir(PDF_DIR):\n",
    "        if not filename.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        pdf_path = os.path.join(PDF_DIR, filename)\n",
    "        file_digest = file_hash(pdf_path)\n",
    "\n",
    "        if file_digest in existing_hashes:\n",
    "            print(f\"‚è≠Ô∏è Skipping already indexed: {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üìÑ New PDF detected: {filename}\")\n",
    "        text = extract_text_with_ocr(pdf_path)\n",
    "        new_documents.append(Document(page_content=text, metadata={\"source\": filename}))\n",
    "        new_hashes.add(file_digest)\n",
    "\n",
    "    # No new docs? Load and return existing vector store\n",
    "    if not new_documents:\n",
    "        print(\"‚úÖ No new documents found.\")\n",
    "        return FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    print(\"‚úÇÔ∏è Splitting documents...\")\n",
    "    splitter = SemanticChunker(embedding_model, chunk_size=1000)\n",
    "    new_chunks = splitter.split_documents(new_documents)\n",
    "\n",
    "    print(\"üì¶ Updating FAISS vector store...\")\n",
    "    if os.path.exists(FAISS_INDEX_PATH + \".faiss\"):\n",
    "        vectorstore = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "        vectorstore.add_documents(new_chunks)\n",
    "    else:\n",
    "        vectorstore = FAISS.from_documents(new_chunks, embeddings)\n",
    "\n",
    "    vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "\n",
    "    # Save combined hashes\n",
    "    updated_hashes = existing_hashes.union(new_hashes)\n",
    "    save_hashes(updated_hashes)\n",
    "    print(f\"‚úÖ Stored {len(updated_hashes)} file hashes in {HASH_STORE_PATH}\")\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fd097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_vectorstore(embeddings):\n",
    "    return update_faiss_index(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6db16815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistentChatMessageHistory(ChatMessageHistory):\n",
    "    def __init__(self, session_id: str):\n",
    "        super().__init__()\n",
    "        self._session_id = session_id\n",
    "        self._file_path = os.path.join(CHAT_HISTORY_DIR, f\"{session_id}.json\")\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        if os.path.exists(self._file_path):\n",
    "            with open(self._file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw = json.load(f)\n",
    "                self.messages = [self._dict_to_message(msg) for msg in raw]\n",
    "\n",
    "    def save(self):\n",
    "        with open(self._file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([self._message_to_dict(msg) for msg in self.messages], f, indent=2)\n",
    "\n",
    "    def add_message(self, message):\n",
    "        super().add_message(message)\n",
    "        self.save()\n",
    "\n",
    "    def _message_to_dict(self, message):\n",
    "        return {\"type\": message.type, \"content\": message.content}   \n",
    "\n",
    "    def _dict_to_message(self, data):\n",
    "        from langchain_core.messages import HumanMessage, AIMessage\n",
    "        return HumanMessage(content=data[\"content\"]) if data[\"type\"] == \"human\" else AIMessage(content=data[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a136b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create RAG Chain with Story Extraction Prompt ===\n",
    "def setup_rag_chain_with_history(session_id: str, embeddings):\n",
    "    vectorstore = load_or_create_vectorstore(embeddings)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 7})\n",
    "\n",
    "    # llm = ChatOpenAI(\n",
    "    # model=OPENAI_MODEL,\n",
    "    # temperature=0,\n",
    "    # openai_api_key=OPENAI_API_KEY\n",
    "    # )\n",
    "    # llm = Ollama(model=\"llama3.2:latest\")  # or any model like \"mistral\", \"phi3\", etc.\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=LLM_DEPLOYMENT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are an AI assistant helping users retrieve development results from UTF annual reports.\\n\\n\"\n",
    "     \"Your main goal is to extract and summarize *results stories* when possible.\\n\\n\"\n",
    "     \"Each results story should include:\\n\"\n",
    "     \"1. A Bold short, descriptive title (5‚Äì10 words)\\n\"\n",
    "     \"2. A summary of the outcome or impact (5‚Äì6 sentences) with bold summary title\\n\"\n",
    "     \"3. Structured metadata:\\n\"\n",
    "     \"   - **Region**\\n\"\n",
    "     \"   - **Sector**\\n\"\n",
    "     \"   - **Donor/Fund**\\n\"\n",
    "     \"   - **Source Document and Page**\\n\\n\"\n",
    "     \"üëâ If you **find stories** related to the user‚Äôs question, present them in the structured format above. Make proper headings and make them bold, dont put ## instead of making bold\\n\"\n",
    "     \"üëâ If **no full stories** are available, **fallback to answering the user's question** based on the relevant context from the document.\\n\\n\"\n",
    "     \"Be clear and informative. Never make up facts.\\n\\n\"\n",
    "     \"Context:\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    return RunnableWithMessageHistory(\n",
    "        rag_chain,\n",
    "        lambda session_id: PersistentChatMessageHistory(session_id),\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40d96ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run a Query ===\n",
    "def run_query(session_id: str, question: str):\n",
    "    rag_chain = setup_rag_chain_with_history(session_id, embeddings)\n",
    "    result = rag_chain.invoke(\n",
    "        {\"input\": question},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " give me two examples of how the MDTF supported private sector job creation in 2020\n",
      "üîÑ Checking for new documents...\n",
      "‚è≠Ô∏è Skipping already indexed: 2020TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping already indexed: 2021TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping already indexed: 2022TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping already indexed: 2023TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping already indexed: 2024TrustFundAnnualReports.pdf\n",
      "‚úÖ No new documents found.\n",
      "üß† **Example 1: IFC‚Äôs Fast-Track COVID-19 Facility Supporting Private Sector Jobs**\n",
      "\n",
      "**Summary:**  \n",
      "In 2020, the IFC launched its Fast-Track COVID-19 Facility, which increased to $8.6 billion, to support private sector job creation during the pandemic. The facility provided $7.4 billion to finance 103 projects that offered liquidity, working capital, and trade financing to keep companies operational, especially in industries most affected by COVID-19. This initiative included a Base of the Pyramid Program aimed at supporting the poorest and hardest-hit populations, initially launched with $400 million and later receiving an additional $200 million in 2022. By maintaining business operations, the facility helped preserve jobs and stabilize economic activity in fragile and conflict-affected areas. This approach demonstrated how targeted financial support can sustain employment during crises.\n",
      "\n",
      "- **Region:** Global (including fragile and conflict-affected areas)  \n",
      "- **Sector:** Private Sector / Job Creation  \n",
      "- **Donor/Fund:** IFC Fast-Track COVID-19 Facility  \n",
      "- **Source Document and Page:** WBG Trust Fund Annual Report 2022, page 44-45  \n",
      "\n",
      "---\n",
      "\n",
      "**Example 2: World Bank Emergency Cash Transfers to Support Vulnerable Workers**\n",
      "\n",
      "**Summary:**  \n",
      "The MDTF supported private sector job creation indirectly by funding emergency cash transfer programs in countries like Bangladesh and Colombia during 2020. In Bangladesh, the Human Capital Umbrella Program helped integrate economic inclusion components into major cash transfer schemes, enabling low-income wage earners to better secure employment post-pandemic. In Colombia, grant financing from the State and Peacebuilding Fund (SPF) provided emergency cash transfers to vulnerable migrants and Venezuelan refugees, mitigating COVID-19 spread and easing social tensions with host communities. These interventions helped stabilize vulnerable populations‚Äô livelihoods, supporting their continued participation in local labor markets and private sector activities.\n",
      "\n",
      "- **Region:** Bangladesh and Colombia  \n",
      "- **Sector:** Social Protection / Private Sector Employment Support  \n",
      "- **Donor/Fund:** Human Capital Umbrella Program; State and Peacebuilding Fund (SPF)  \n",
      "- **Source Document and Page:** WBG Trust Fund Annual Report 2022, page 44-45\n"
     ]
    }
   ],
   "source": [
    "session_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "q = \"give me two examples of how the MDTF supported private sector job creation in 2020\" \n",
    "\n",
    "print(f\"\\n {q}\")\n",
    "answer = run_query(session_id, q)\n",
    "print(f\"üß† {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
