{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9708e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import hashlib\n",
    "import fitz\n",
    "import uuid\n",
    "import platform\n",
    "import pickle\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d523803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file for Azure keys/config\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d65e9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set path to tesseract executable on Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1633a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI config\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_MODEL=\"gpt-4.1-mini\"\n",
    "OPENAI_EMBEDDING_MODEL=\"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05fe43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Azure OpenAI LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=OPENAI_API_MODEL,\n",
    "    temperature=0,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1401f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Setup Azure Embeddings & LLM\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=OPENAI_EMBEDDING_MODEL,\n",
    "    chunk_size=1000  # Optional: controls how many docs are embedded per batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c80cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Path Configs ===\n",
    "PDF_DIR = \"./source_docs\"\n",
    "FAISS_INDEX_PATH = \"./store\"  # ‚úÖ Now points directly to where index.faiss is\n",
    "METADATA_STORE_PATH = \"./store/index.pkl\"  # ‚úÖ Points to the actual pickle file\n",
    "HASH_STORE_PATH = \"./hashes/pdf_hashes.txt\"\n",
    "output_dir = \"./markdowns\"\n",
    "COMBINED_DIR = \"./combined\"\n",
    "COMBINED_MD_PATH = \"./combined/combined.md\"\n",
    "COMBINED_MD_HASH_STORE = \"./hashes/combined_md_hash.txt\"\n",
    "image_dir = os.path.join(output_dir, \"images\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(image_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ed3a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_hash(filepath):\n",
    "    h = hashlib.sha256()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        while chunk := f.read(8192):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_pdf_hashes():\n",
    "    if not os.path.exists(HASH_STORE_PATH):\n",
    "        return set()\n",
    "    with open(HASH_STORE_PATH, \"r\") as f:\n",
    "        return set(line.strip() for line in f)\n",
    "\n",
    "def save_pdf_hashes(hashes: set):\n",
    "    with open(HASH_STORE_PATH, \"w\") as f:\n",
    "        for h in sorted(hashes):\n",
    "            f.write(f\"{h}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee2e2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_tesseract_path():\n",
    "    system = platform.system()\n",
    "    if system == \"Windows\":\n",
    "        # Common default install location‚Äîchange if needed\n",
    "        possible = [\n",
    "            r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\",\n",
    "            r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
    "        ]\n",
    "        for path in possible:\n",
    "            if os.path.isfile(path):\n",
    "                pytesseract.pytesseract.tesseract_cmd = path\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Tesseract not found in default Windows paths.\")\n",
    "    else:\n",
    "        # On Linux or macOS, tesseract should be in PATH\n",
    "        pytesseract.pytesseract.tesseract_cmd = \"tesseract\"\n",
    "\n",
    "    # Optional: verify it's working\n",
    "    try:\n",
    "        version = os.popen(f'\"{pytesseract.pytesseract.tesseract_cmd}\" --version').read()\n",
    "        print(\"‚úîÔ∏è Tesseract detected:\", version.splitlines()[0])\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error verifying Tesseract at '{pytesseract.pytesseract.tesseract_cmd}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dcfa1260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path_or_bytes):\n",
    "    configure_tesseract_path()\n",
    "\n",
    "    if isinstance(image_path_or_bytes, bytes):\n",
    "        image = Image.open(io.BytesIO(image_path_or_bytes))\n",
    "    else:\n",
    "        image = Image.open(image_path_or_bytes)\n",
    "\n",
    "    # Step 1: OCR text extraction\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "\n",
    "    # Step 2: Prepare image for OpenAI\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    b64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "    data_uri = f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "    # Step 3: LLM-based image description\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Please describe the image's layout, key elements, and any text it contains. This is part of an annual development report.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=300\n",
    "        )\n",
    "        image_description = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Azure image description failed: {e}\")\n",
    "        image_description = \"(No image description due to policy filter or API error)\"\n",
    "\n",
    "\n",
    "    # Step 4: Combine and return\n",
    "    return f\"{ocr_text.strip()}\\n\\n**Image Description:**\\n{image_description.strip()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f26c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageStat\n",
    "\n",
    "def is_blank_or_low_text(image_bytes, threshold=5):\n",
    "    \"\"\"Return True if image is mostly blank or low-content.\"\"\"\n",
    "    image = Image.open(io.BytesIO(image_bytes)).convert(\"L\")  # grayscale\n",
    "    stat = ImageStat.Stat(image)\n",
    "    return stat.stddev[0] < threshold  # low stddev = low variation = blank\n",
    "\n",
    "def extract_pdf_as_markdown(file_path, base_filename, image_dir):\n",
    "    doc = fitz.open(file_path)\n",
    "    markdown = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        markdown += f\"\\n## Page {page_num + 1}\\n\"\n",
    "        markdown += page.get_text(\"text\") + \"\\n\"\n",
    "\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            ext = base_image[\"ext\"]\n",
    "\n",
    "            image_filename = f\"{base_filename}_p{page_num+1}_img{img_index+1}.{ext}\"\n",
    "            image_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "            if os.path.exists(image_path):\n",
    "                print(f\"üîÅ Skipping already processed image: {image_filename}\")\n",
    "                continue\n",
    "\n",
    "            # Skip low-content images\n",
    "            if is_blank_or_low_text(image_bytes):\n",
    "                print(f\"üö´ Skipping blank/low-content image: {image_filename}\")\n",
    "                continue\n",
    "\n",
    "            # Save image\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "\n",
    "            # OCR + Vision\n",
    "            ocr_text = extract_text_from_image(image_bytes)\n",
    "\n",
    "            markdown += f\"\\n**Image {img_index + 1} OCR + Description:**\\n```\\n{ocr_text.strip()}\\n```\\n\"\n",
    "            markdown += f\"![Image {img_index + 1}](images/{image_filename})\\n\"\n",
    "\n",
    "    return markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c882b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs_to_markdown(pdf_dir=PDF_DIR, output_dir=\"./markdowns\"):\n",
    "    image_dir = os.path.join(output_dir, \"images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "    existing_hashes = load_pdf_hashes()\n",
    "    new_hashes = set()\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        pdf_digest = file_hash(pdf_path)\n",
    "\n",
    "        if pdf_digest in existing_hashes:\n",
    "            print(f\"‚è≠Ô∏è Skipping (already processed): {pdf_file}\")\n",
    "            continue\n",
    "\n",
    "        base_filename = os.path.splitext(pdf_file)[0]\n",
    "        safe_name = re.sub(r\"[^\\w\\-_. ]\", \"_\", base_filename)\n",
    "\n",
    "        print(f\"üìÑ Processing: {pdf_file}...\")\n",
    "\n",
    "        try:\n",
    "            markdown = extract_pdf_as_markdown(pdf_path, safe_name, image_dir)\n",
    "            md_path = os.path.join(output_dir, f\"{safe_name}.md\")\n",
    "\n",
    "            with open(md_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "                md_file.write(markdown)\n",
    "\n",
    "            print(f\"‚úÖ Markdown saved: {md_path}\")\n",
    "            new_hashes.add(pdf_digest)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to process {pdf_file}: {e}\")\n",
    "\n",
    "    # Save updated hash store\n",
    "    all_hashes = existing_hashes.union(new_hashes)\n",
    "    save_pdf_hashes(all_hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15369c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_markdown_files(markdown_dir=\"./markdowns\", combined_path=COMBINED_MD_PATH, hash_store=COMBINED_MD_HASH_STORE):\n",
    "    os.makedirs(os.path.dirname(combined_path), exist_ok=True)\n",
    "\n",
    "    markdown_files = sorted([\n",
    "        f for f in os.listdir(markdown_dir)\n",
    "        if f.endswith(\".md\") and not f.startswith(\".\") and f != os.path.basename(combined_path)\n",
    "    ])\n",
    "\n",
    "    combined = \"\"\n",
    "    for md_file in markdown_files:\n",
    "        with open(os.path.join(markdown_dir, md_file), \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read().strip()\n",
    "            combined += f\"\\n\\n# --- Start of: {md_file} ---\\n\\n{content}\\n\\n# --- End of: {md_file} ---\\n\"\n",
    "\n",
    "    # Always write the combined.md file\n",
    "    with open(combined_path, \"w\", encoding=\"utf-8\") as out:\n",
    "        out.write(combined.strip())\n",
    "\n",
    "    # Save hash\n",
    "    new_hash = hashlib.sha256(combined.encode(\"utf-8\")).hexdigest()\n",
    "    with open(hash_store, \"w\") as f:\n",
    "        f.write(new_hash)\n",
    "\n",
    "    print(f\"‚úÖ Combined markdown updated: {combined_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68dacc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_combined_md_updated():\n",
    "    if not os.path.exists(COMBINED_MD_PATH):\n",
    "        print(\"‚ùå Combined markdown file does not exist.\")\n",
    "        return True\n",
    "\n",
    "    if not os.path.exists(COMBINED_MD_HASH_STORE):\n",
    "        print(\"‚ùå Combined hash file does not exist.\")\n",
    "        return True\n",
    "\n",
    "    with open(COMBINED_MD_PATH, \"rb\") as f:\n",
    "        current_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "\n",
    "    with open(COMBINED_MD_HASH_STORE, \"r\") as f:\n",
    "        stored_hash = f.read().strip()\n",
    "\n",
    "    if current_hash != stored_hash:\n",
    "        print(\"üÜï Combined.md hash has changed.\")\n",
    "        return True\n",
    "\n",
    "    print(\"‚úÖ Combined.md has not changed.\")\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bfd85b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï Combined.md hash has changed.\n",
      "üÜï Combined.md hash has changed.\n"
     ]
    }
   ],
   "source": [
    "is_combined_md_updated()  # No output unless captured or printed\n",
    "\n",
    "result = is_combined_md_updated()  # still no print output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "847c9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_faiss_index(store, index_path=FAISS_INDEX_PATH):\n",
    "    store.save_local(index_path)\n",
    "\n",
    "def load_faiss_index(embeddings, index_path=FAISS_INDEX_PATH):\n",
    "    return FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "889af163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_update_vector_store(embeddings, force=False):\n",
    "    if not force and not is_combined_md_updated() and \\\n",
    "       os.path.exists(FAISS_INDEX_PATH) and os.path.exists(METADATA_STORE_PATH):\n",
    "        print(\"üì¶ FAISS is up-to-date. Loading existing index...\")\n",
    "        return load_faiss_index()\n",
    "\n",
    "    print(\"üîç Reading combined markdown...\")\n",
    "    with open(COMBINED_MD_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    # ----------- Chunking -----------\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.create_documents([raw_text])\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata = {\"source\": \"combined.md\"}\n",
    "\n",
    "    # ----------- Embedding -----------\n",
    "    print(\"‚öôÔ∏è Generating embeddings...\")\n",
    "    doc_embeddings = [embeddings.embed_query(doc.page_content) for doc in tqdm(chunks, desc=\"Embedding\")]\n",
    "\n",
    "    # ----------- FAISS Store -----------\n",
    "    vector_store = FAISS.from_embeddings(\n",
    "        text_embeddings=[(doc.page_content, emb) for doc, emb in zip(chunks, doc_embeddings)],\n",
    "        embedding=embeddings,\n",
    "        metadatas=[doc.metadata for doc in chunks]\n",
    "    )\n",
    "\n",
    "    save_faiss_index(vector_store)\n",
    "\n",
    "    # Save new hash\n",
    "    with open(COMBINED_MD_HASH_STORE, \"w\") as f:\n",
    "        f.write(hashlib.sha256(raw_text.encode(\"utf-8\")).hexdigest())\n",
    "\n",
    "    print(\"‚úÖ Vector store saved.\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52fa1963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≠Ô∏è Skipping (already processed): 2020TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping (already processed): 2021TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping (already processed): 2022TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping (already processed): 2023TrustFundAnnualReports.pdf\n",
      "‚è≠Ô∏è Skipping (already processed): 2024TrustFundAnnualReports.pdf\n",
      "‚úÖ Combined markdown updated: ./combined/combined.md\n",
      "üÜï Combined.md hash has changed.\n",
      "üîç Reading combined markdown...\n",
      "‚öôÔ∏è Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m combine_markdown_files()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Build or load vector store\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m build_or_update_vector_store(embeddings, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[73], line 24\u001b[0m, in \u001b[0;36mbuild_or_update_vector_store\u001b[1;34m(embeddings, force)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# ----------- Embedding -----------\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚öôÔ∏è Generating embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m doc_embeddings \u001b[38;5;241m=\u001b[39m [embeddings\u001b[38;5;241m.\u001b[39membed_query(doc\u001b[38;5;241m.\u001b[39mpage_content) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(chunks, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ----------- FAISS Store -----------\u001b[39;00m\n\u001b[0;32m     27\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_embeddings(\n\u001b[0;32m     28\u001b[0m     text_embeddings\u001b[38;5;241m=\u001b[39m[(doc\u001b[38;5;241m.\u001b[39mpage_content, emb) \u001b[38;5;28;01mfor\u001b[39;00m doc, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunks, doc_embeddings)],\n\u001b[0;32m     29\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     30\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39m[doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     31\u001b[0m )\n",
      "Cell \u001b[1;32mIn[73], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# ----------- Embedding -----------\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚öôÔ∏è Generating embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m doc_embeddings \u001b[38;5;241m=\u001b[39m [embeddings\u001b[38;5;241m.\u001b[39membed_query(doc\u001b[38;5;241m.\u001b[39mpage_content) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(chunks, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ----------- FAISS Store -----------\u001b[39;00m\n\u001b[0;32m     27\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_embeddings(\n\u001b[0;32m     28\u001b[0m     text_embeddings\u001b[38;5;241m=\u001b[39m[(doc\u001b[38;5;241m.\u001b[39mpage_content, emb) \u001b[38;5;28;01mfor\u001b[39;00m doc, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunks, doc_embeddings)],\n\u001b[0;32m     29\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     30\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39m[doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:704\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \n\u001b[0;32m    698\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_documents([text])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(\n\u001b[0;32m    672\u001b[0m     texts, engine\u001b[38;5;241m=\u001b[39mengine, chunk_size\u001b[38;5;241m=\u001b[39mchunk_size\n\u001b[0;32m    673\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m embed_with_retry(\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size],\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:129\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    123\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    132\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    133\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    134\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    135\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    136\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    137\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    138\u001b[0m     ),\n\u001b[0;32m    139\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:972\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    970\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    973\u001b[0m         request,\n\u001b[0;32m    974\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    976\u001b[0m     )\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    978\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process PDFs ‚ûú Markdown\n",
    "process_all_pdfs_to_markdown()\n",
    "\n",
    "# Combine all markdown files\n",
    "combine_markdown_files()\n",
    "\n",
    "# Build or load vector store\n",
    "vector_store = build_or_update_vector_store(embeddings, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_chain(embeddings, llm):\n",
    "    # Load or update vector store\n",
    "    vectorstore = build_or_update_vector_store(embeddings)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 7})\n",
    "\n",
    "    # Prompt Template (no chat history)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         \"You are an AI assistant that helps users extract and summarize **development results stories** from provided documents.\\n\\n\"\n",
    "         \"Your goal is to detect and present results or impact-related content from the context.\\n\\n\"\n",
    "         \"**If results stories are present**, follow this format:\\n\"\n",
    "         \"1. **Bold Title** (5‚Äì10 words)\\n\"\n",
    "         \"2. **Bold Summary:** 4‚Äì5 sentences describing the outcome or impact\\n\"\n",
    "         \"3. Structured metadata:\\n\"\n",
    "         \"   - **Region** (if available)\\n\"\n",
    "         \"   - **Sector**\\n\"\n",
    "         \"   - **Donor/Fund** (if mentioned)\\n\"\n",
    "         \"   - **Source Document** (name of the document)\\n\\n\"\n",
    "         \"**If no full results stories are found**, fallback to a concise and informative answer using the best available context from the documents.\\n\\n\"\n",
    "         \"NEVER fabricate information that is not clearly supported by the context.\\n\\n\"\n",
    "         \"Context:\\n{context}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    # Chain assembly\n",
    "    document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    return rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d96ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run a Query ===\n",
    "def run_query(question: str):\n",
    "    rag_chain = setup_rag_chain(embeddings, llm)\n",
    "    result = rag_chain.invoke(\n",
    "        {\"input\": question}\n",
    "    )\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"give me two examples of how the MDTF supported private sector job creation in 2020\" \n",
    "\n",
    "print(f\"\\n {q}\")\n",
    "answer = run_query(q)\n",
    "print(f\"üß† {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
