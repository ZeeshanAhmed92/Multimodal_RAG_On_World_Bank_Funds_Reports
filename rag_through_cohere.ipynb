{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c42f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import hashlib, json\n",
    "from io import BytesIO\n",
    "import os\n",
    "import cohere\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from cohere import Client  \n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ca3f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "227d8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.ClientV2(api_key=os.getenv(\"COHERE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3dfbace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cohere.client_v2.ClientV2 at 0x727d8066fdd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2b72ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8029d154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x727d80674080>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cc5731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sha256(data: bytes) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(data)\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb1c2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images_with_hashes(input_pdf: str, images_folder: str = 'images', hashes_folder: str = 'hashes', dpi: int = 300, \n",
    "    fmt: str = 'png', hash_filename: str = 'pages_hashes.json'):\n",
    "\n",
    "    pdf = Path(input_pdf)\n",
    "    images_dir = Path(images_folder)\n",
    "    hashes_dir = Path(hashes_folder)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    hashes_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    hash_path = hashes_dir / hash_filename\n",
    "\n",
    "    # Load existing manifest if exists\n",
    "    if hash_path.exists():\n",
    "        with open(hash_path, 'r') as f:\n",
    "            hash = json.load(f)\n",
    "    else:\n",
    "        hash = {}\n",
    "\n",
    "    pages = convert_from_path(str(pdf), dpi=dpi)\n",
    "    updated = False\n",
    "\n",
    "    for page_num, page in enumerate(pages, start=1):\n",
    "        key = f\"{pdf.stem}_page_{page_num}\"\n",
    "        if key in hash:\n",
    "            print(f\"✔ Skipping page {page_num}, already processed.\")\n",
    "            continue\n",
    "\n",
    "        # Convert image to bytes for hashing\n",
    "        buffer = BytesIO()\n",
    "        page.save(buffer, format=fmt.upper())\n",
    "        img_bytes = buffer.getvalue()\n",
    "\n",
    "        # Compute hash\n",
    "        short_hash = compute_sha256(img_bytes)\n",
    "\n",
    "        # Save image without hash in name\n",
    "        filename = f\"{pdf.stem}_page_{page_num}.{fmt}\"\n",
    "        image_path = images_dir / filename\n",
    "        image_path.write_bytes(img_bytes)\n",
    "        print(f\"🖼️ Saved: {filename}\")\n",
    "\n",
    "        # Update manifest\n",
    "        hash[key] = {\"filename\": filename, \"hash\": short_hash}\n",
    "        updated = True\n",
    "\n",
    "    # Write updated manifest\n",
    "    if updated:\n",
    "        with open(hash_path, 'w') as f:\n",
    "            json.dump(hash, f, indent=2)\n",
    "        print(f\"📘 Updated hashes at {hash_path}\")\n",
    "    else:\n",
    "        print(\"✅ No new pages — hashes unchanged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ff8a159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Skipping page 1, already processed.\n",
      "✔ Skipping page 2, already processed.\n",
      "✔ Skipping page 3, already processed.\n",
      "✔ Skipping page 4, already processed.\n",
      "✔ Skipping page 5, already processed.\n",
      "✔ Skipping page 6, already processed.\n",
      "✔ Skipping page 7, already processed.\n",
      "✔ Skipping page 8, already processed.\n",
      "✔ Skipping page 9, already processed.\n",
      "✔ Skipping page 10, already processed.\n",
      "✔ Skipping page 11, already processed.\n",
      "✔ Skipping page 12, already processed.\n",
      "✔ Skipping page 13, already processed.\n",
      "✔ Skipping page 14, already processed.\n",
      "✔ Skipping page 15, already processed.\n",
      "✔ Skipping page 16, already processed.\n",
      "✅ No new pages — hashes unchanged.\n"
     ]
    }
   ],
   "source": [
    "pdf_to_images_with_hashes(\"source_docs/2024TrustFundAnnualReports.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some helper functions to resize images and to convert them to base64 format\n",
    "# max_pixels = 1568*1568  #Max resolution for images\n",
    "\n",
    "# # Resize too large images\n",
    "# def resize_image(pil_image):\n",
    "#     org_width, org_height = pil_image.size\n",
    "\n",
    "#     # Resize image if too large\n",
    "#     if org_width * org_height > max_pixels:\n",
    "#         scale_factor = (max_pixels / (org_width * org_height)) ** 0.5\n",
    "#         new_width = int(org_width * scale_factor)\n",
    "#         new_height = int(org_height * scale_factor)\n",
    "#         pil_image.thumbnail((new_width, new_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51f99989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to a base64 string before sending it to the API\n",
    "def base64_from_image(img_path):\n",
    "    pil_image = PIL.Image.open(img_path)\n",
    "    img_format = pil_image.format if pil_image.format else \"PNG\"\n",
    "\n",
    "    # resize_image(pil_image)\n",
    "\n",
    "    with io.BytesIO() as img_buffer:\n",
    "        pil_image.save(img_buffer, format=img_format)\n",
    "        img_buffer.seek(0)\n",
    "        img_data = f\"data:image/{img_format.lower()};base64,\"+base64.b64encode(img_buffer.read()).decode(\"utf-8\")\n",
    "\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fb4c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding images:   0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PIL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m doc_embeddings = []\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm.tqdm(img_paths, desc=\u001b[33m\"\u001b[39m\u001b[33mEmbedding images\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     15\u001b[39m     api_input_document = {\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mbase64_from_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m},\n\u001b[32m     18\u001b[39m         ]\n\u001b[32m     19\u001b[39m     }\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Call Cohere Embed v4.0\u001b[39;00m\n\u001b[32m     22\u001b[39m     api_response = co.embed(\n\u001b[32m     23\u001b[39m         model=\u001b[33m\"\u001b[39m\u001b[33membed-v4.0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m         input_type=\u001b[33m\"\u001b[39m\u001b[33msearch_document\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m         embedding_types=[\u001b[33m\"\u001b[39m\u001b[33mfloat\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     26\u001b[39m         inputs=[api_input_document],\n\u001b[32m     27\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mbase64_from_image\u001b[39m\u001b[34m(img_path)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbase64_from_image\u001b[39m(img_path):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     pil_image = \u001b[43mPIL\u001b[49m.Image.open(img_path)\n\u001b[32m      4\u001b[39m     img_format = pil_image.format \u001b[38;5;28;01mif\u001b[39;00m pil_image.format \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPNG\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# resize_image(pil_image)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'PIL' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Cohere\n",
    "co = Client(api_key=os.getenv(\"COHERE_API_KEY\"))  # Replace with your key\n",
    "\n",
    "# Local images folder\n",
    "img_folder = \"images\"  # or wherever your images are saved\n",
    "img_paths = sorted([\n",
    "    os.path.join(img_folder, f)\n",
    "    for f in os.listdir(img_folder)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "doc_embeddings = []\n",
    "\n",
    "for img_path in tqdm.tqdm(img_paths, desc=\"Embedding images\"):\n",
    "    api_input_document = {\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": base64_from_image(img_path)},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Call Cohere Embed v4.0\n",
    "    api_response = co.embed(\n",
    "        model=\"embed-v4.0\",\n",
    "        input_type=\"search_document\",\n",
    "        embedding_types=[\"float\"],\n",
    "        inputs=[api_input_document],\n",
    "    )\n",
    "\n",
    "    # Extract embedding\n",
    "    emb = np.asarray(api_response.embeddings.float[0])\n",
    "    doc_embeddings.append(emb)\n",
    "\n",
    "doc_embeddings = np.vstack(doc_embeddings)\n",
    "print(\"\\n✅ Embeddings shape:\", doc_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-chroma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
